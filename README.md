# Art Generation GANs
Experimenting with DCGANs for generating art. 

## Model Architecture
The architecture used in this DCGAN implementation is drawn directly from the [DCGAN research paper](https://arxiv.org/abs/1511.06434) and the [PyTorch DCGAN tutorial](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html). 
![alt text](https://pytorch.org/tutorials/_images/dcgan_generator.png)

The input to the generator is a 100-dimensional random latent feature vector, which goes through a series of convolutional transpose layers to generate a 64x64 colored image. For 128x128 image generation, one extra convolutional transpose layer is added. 

The discriminator takes a colored 64x64 image as input and outputs a probability that corresponds to the authenticity of the inputted image. Similar to the generator, one additional convolutional layer is added to the discriminator to allow it to classify 128x128 images. 

All hyperparameters, like latent feature vector size, learning rates, batch sizes, and feature map sizes were drawn directly from the DCGAN paper. Batch size was changed from original value of 128 to 64. 


## Datasets
[Find the Ancient Chinese Art dataset here](https://github.com/ychen93/Chinese-Painting-Dataset/blob/master/data.zip)

The zip file for this dataset contains two copies of the same data, with one copy formatted for MacOSX.

## Results
Sample 64x64 images generated by the trained network. The left images are training examples and the right images are generated examples. 

![new_gan_output](https://user-images.githubusercontent.com/77770114/106233347-4ee44880-61c4-11eb-817f-11933449c62b.png)

While some images are low-quality, others are able to replicate structures like flowers commonly seen in the training images. 

Sample 128x128 images generated by the trained network. The left images are training examples and the right images are generated examples.

![gan-results-128](https://user-images.githubusercontent.com/77770114/105312028-91d26a80-5b8b-11eb-8096-9bccf5fb574d.png)

Generated images are not quite as clear because of a lack of training time. With more epochs, the GAN would be able to generate satisfactory 128x128 images. 

## Trying the Model
Follow these steps to create some of your own images! 

To use the parameters provided in the repo:
1. Download the dataset. Unzip it and delete the MACOSX folder, as this contains duplicate images. 
2. Download the paramters for either the 64px DCGAN or the 128px DCGAN.
3. Open either the DCGAN_64 or DCGAN_128 Jupyter notebook.
4. Load the parameters file into the Jupyter notebook.
5. Scroll down in the notebook to the code cell that loads in parameters and run this cell to load in the model parameters. Change the path according to the directory in which the model parameters were stored. There are different parameter options to load in, with the number at the end of each file corresponding to how many epochs that set of parameters trained for.
6. Run the last cell to generate new images. 

The notebooks also provide instructions for re-training the model from scratch. 


